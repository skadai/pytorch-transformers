{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 情感极性指标计算&异常预测查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiuser/.pyenv/versions/3.6.6/envs/sk-torch/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# from utils_squad_multi_plus import read_ecom_examples as cc\n",
    "# from utils_squad_multi_plus import TRANS_SUBTYPE\n",
    "from utils_skincare import read_ecom_examples as cc\n",
    "from utils_skincare import TRANS_SUBTYPE\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def calc_polar_metric(dataset, preds_polar, preds_op,preds_as,need_print=False):\n",
    "    polar_preds = []\n",
    "    polar_labels = []\n",
    "    polar_map={\n",
    "        '正面':5,\n",
    "        '负面':1,\n",
    "        \"中性\":3\n",
    "    }\n",
    "    wrong = 0\n",
    "    raw_datas = []\n",
    "    for d in dataset:\n",
    "        doc_tokens = d.doc_tokens.split(' ',1)[-1]\n",
    "        \n",
    "        polar_pred = preds_polar[d.qas_id].replace(\" \",\"\")\n",
    "        polar_label = d.polar_answer_text\n",
    "        polar_preds.append(polar_map.get(polar_pred, 0))\n",
    "        polar_labels.append(polar_map.get(polar_label,0))\n",
    "        \n",
    "        opinion_pred = preds_op[d.qas_id].replace(\" \",\"\")\n",
    "        opinion_label = d.op_answer_text\n",
    "        raw_datas.append((d.question_text, doc_tokens, polar_label, polar_pred, opinion_label, opinion_pred))\n",
    "        if need_print and  polar_label != polar_pred:\n",
    "#         if need_print and d.orig_answer_text != preds_as[d.qas_id].replace(\" \",\"\") and preds_as[d.qas_id].replace(\" \",\"\")==\"\": \n",
    "            wrong += 1\n",
    "            print(d.doc_tokens)\n",
    "            print('label', 'aspect', d.orig_answer_text, 'opinion', opinion_label, 'polar', polar_label)\n",
    "            print('predict','aspect', preds_as[d.qas_id].replace(\" \",\"\"), 'opinion', opinion_pred ,\n",
    "                 'polar', polar_pred)\n",
    "            print(f'***********************{wrong}********************************')\n",
    "\n",
    "\n",
    "    s = precision_recall_fscore_support(polar_labels, polar_preds)\n",
    "    df_temp = pd.DataFrame(np.array(s).T, columns=['prec', 'recall', 'f1','support'])\n",
    "    df_temp['subtype'] = subtype\n",
    "    \n",
    "    df_temp['polarity'] = [0,1,3,5] if len(df_temp)==4 else [0,1,5]\n",
    "    df_raw = pd.DataFrame(raw_datas, columns=['subtype', 'text', 'label','predict','op_label','op_pred'])\n",
    "    return df_temp, df_raw\n",
    "\n",
    "\n",
    "\n",
    "###  替换为待评估的品类\n",
    "data_dir='skincare_v2'\n",
    "\n",
    "target_dir = f\"/data/projects/bert_pytorch/{data_dir}_out/all_in_one_v2/checkpoint-3000\"\n",
    "need_print=False\n",
    "\n",
    "\n",
    "df_temp_polar = pd.DataFrame()\n",
    "df_temp_raw = pd.DataFrame()\n",
    "dirlist= os.listdir(target_dir)\n",
    "# dirlist = ['Greasy']\n",
    "for dirname in dirlist:\n",
    "    subtype = dirname.replace('_',\" \").replace('.','/')\n",
    "    if  subtype in TRANS_SUBTYPE:\n",
    "        polar_pred_path = os.path.join(target_dir, dirname, 'polar_predictions_.json')\n",
    "        opinion_pred_path = os.path.join(target_dir, dirname, 'op_predictions_.json')\n",
    "        aspect_pred_path = os.path.join(target_dir, dirname, 'predictions_.json')\n",
    "\n",
    "        label_path = f'/data/projects/bert_pytorch/{data_dir}/{dirname}/dev.json'\n",
    "        dataset = cc(label_path, True, subtype)\n",
    "        preds_polar = json.load(open(polar_pred_path, 'r'))\n",
    "        preds_op = json.load(open(opinion_pred_path, 'r'))\n",
    "        preds_as = json.load(open(aspect_pred_path, 'r'))\n",
    "        df_temp, df_raw  = calc_polar_metric(dataset, \n",
    "                                            preds_polar,\n",
    "                                            preds_op,\n",
    "                                            preds_as, \n",
    "                                            need_print=need_print)\n",
    "        df_temp_polar = pd.concat([df_temp_polar, df_temp])\n",
    "        df_temp_raw = pd.concat([df_temp_raw, df_raw])\n",
    "        \n",
    "# df_temp_polar.groupby('subtype').size()\n",
    "df_temp_polar['weight_f1']=df_temp_polar.apply(lambda x: x['f1']*x['support'],axis=1)\n",
    "df_temp_raw['ok?'] = df_temp_raw.apply(lambda x: x['predict']==x['label'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.887772210516138, 0.7690163325516203)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 计算加权F1\n",
    "f1_pos = df_temp_polar[df_temp_polar.polarity==5]['weight_f1'].sum()/df_temp_polar[df_temp_polar.polarity==5]['support'].sum()\n",
    "f1_neg = df_temp_polar[df_temp_polar.polarity==1]['weight_f1'].sum()/df_temp_polar[df_temp_polar.polarity==1]['support'].sum()\n",
    "\n",
    "f1_pos, f1_neg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "      <th>subtype</th>\n",
       "      <th>polarity</th>\n",
       "      <th>weight_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Fat Granule</td>\n",
       "      <td>5</td>\n",
       "      <td>3.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Whitening</td>\n",
       "      <td>5</td>\n",
       "      <td>63.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Irritation</td>\n",
       "      <td>5</td>\n",
       "      <td>96.696429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.945122</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>176.0</td>\n",
       "      <td>Smell</td>\n",
       "      <td>5</td>\n",
       "      <td>160.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.922652</td>\n",
       "      <td>0.932961</td>\n",
       "      <td>0.927778</td>\n",
       "      <td>179.0</td>\n",
       "      <td>Greasy</td>\n",
       "      <td>5</td>\n",
       "      <td>166.072222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.943005</td>\n",
       "      <td>282.0</td>\n",
       "      <td>Moisturization</td>\n",
       "      <td>5</td>\n",
       "      <td>265.927461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prec    recall        f1  support         subtype  polarity   weight_f1\n",
       "3  0.400000  0.571429  0.470588      7.0     Fat Granule         5    3.294118\n",
       "3  0.701149  0.655914  0.677778     93.0       Whitening         5   63.033333\n",
       "3  0.863636  0.833333  0.848214    114.0      Irritation         5   96.696429\n",
       "3  0.945122  0.880682  0.911765    176.0           Smell         5  160.470588\n",
       "2  0.922652  0.932961  0.927778    179.0          Greasy         5  166.072222\n",
       "3  0.919192  0.968085  0.943005    282.0  Moisturization         5  265.927461"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_polar[df_temp_polar.polarity==5].sort_values('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_raw.to_csv(f'/data/projects/bert_pytorch/{data_dir}/polar_raw_results_mod_punc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_polar.to_csv(f'/data/projects/bert_pytorch/{data_dir}/asop_mtl_polar_bert_ep5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计情感词极性冲突的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "stat_op_confict = defaultdict(dict)\n",
    "\n",
    "for _, line in df_temp_raw.iterrows():\n",
    "    \n",
    "    kw = line['op_pred'] or 'null'\n",
    "    polar = line['predict'] or 'null'\n",
    "    stat_op_confict[kw][polar] = stat_op_confict[kw].get(polar,0)+1\n",
    "\n",
    "idx = 0\n",
    "for k, v in stat_op_confict.items():\n",
    "    total = sum(v.values())\n",
    "#     for i,j in v.items():\n",
    "#         v[i] = round(j/total*100,3)\n",
    "    if len(v) > 1:\n",
    "        print(idx,k,v)\n",
    "        idx+=1\n",
    "print(f'共有情感词{len(stat_op_confict)}, 其中存在极性冲突{idx}, 占比{idx/len(stat_op_confict)*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算指标(single)\n",
    "\n",
    "各个subtype分别训练阅读理解模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T09:49:51.454309Z",
     "start_time": "2019-09-10T09:49:25.651878Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try to assess Whitening\n",
      "['{', '  \"exact\": 76.67844522968198,', '  \"f1\": 86.99927085086091,', '  \"total\": 283,', '  \"HasAns_exact\": 61.8421052631579,', '  \"HasAns_f1\": 81.05785296574774,', '  \"HasAns_total\": 152,', '  \"NoAns_exact\": 93.89312977099236,', '  \"NoAns_f1\": 93.89312977099236,', '  \"NoAns_total\": 131,', '  \"best_exact\": 77.03180212014134,', '  \"best_exact_thresh\": -2.5290756225585938,', '  \"best_f1\": 87.35262774132026,', '  \"best_f1_thresh\": -1.942481517791748', '}']\n",
      "try to assess Smell\n",
      "['{', '  \"exact\": 87.22943722943722,', '  \"f1\": 93.25429861144148,', '  \"total\": 462,', '  \"HasAns_exact\": 75.81967213114754,', '  \"HasAns_f1\": 87.22740146920478,', '  \"HasAns_total\": 244,', '  \"NoAns_exact\": 100.0,', '  \"NoAns_f1\": 100.0,', '  \"NoAns_total\": 218,', '  \"best_exact\": 87.22943722943722,', '  \"best_exact_thresh\": -0.056565284729003906,', '  \"best_f1\": 93.25429861144148,', '  \"best_f1_thresh\": -0.056565284729003906', '}']\n",
      "try to assess Irritation\n",
      "['{', '  \"exact\": 81.67420814479638,', '  \"f1\": 89.37460752951841,', '  \"total\": 442,', '  \"HasAns_exact\": 67.36401673640168,', '  \"HasAns_f1\": 81.60492271149423,', '  \"HasAns_total\": 239,', '  \"NoAns_exact\": 98.52216748768473,', '  \"NoAns_f1\": 98.52216748768473,', '  \"NoAns_total\": 203,', '  \"best_exact\": 81.67420814479638,', '  \"best_exact_thresh\": -0.546320915222168,', '  \"best_f1\": 89.37460752951846,', '  \"best_f1_thresh\": -0.546320915222168', '}']\n",
      "try to assess Greasy\n",
      "['{', '  \"exact\": 85.1380042462845,', '  \"f1\": 91.50978391742726,', '  \"total\": 471,', '  \"HasAns_exact\": 72.57383966244726,', '  \"HasAns_f1\": 85.23674356585751,', '  \"HasAns_total\": 237,', '  \"NoAns_exact\": 97.86324786324786,', '  \"NoAns_f1\": 97.86324786324786,', '  \"NoAns_total\": 234,', '  \"best_exact\": 85.35031847133757,', '  \"best_exact_thresh\": -1.256917953491211,', '  \"best_f1\": 91.5522467624379,', '  \"best_f1_thresh\": -1.256917953491211', '}']\n",
      "try to assess Fat Granule\n",
      "['{', '  \"exact\": 96.15384615384616,', '  \"f1\": 97.20279720279721,', '  \"total\": 26,', '  \"HasAns_exact\": 93.75,', '  \"HasAns_f1\": 95.45454545454545,', '  \"HasAns_total\": 16,', '  \"NoAns_exact\": 100.0,', '  \"NoAns_f1\": 100.0,', '  \"NoAns_total\": 10,', '  \"best_exact\": 96.15384615384616,', '  \"best_exact_thresh\": -3.769637107849121,', '  \"best_f1\": 97.20279720279721,', '  \"best_f1_thresh\": -3.769637107849121', '}']\n",
      "try to assess Moisturization\n",
      "['{', '  \"exact\": 82.6955074875208,', '  \"f1\": 88.661242005668,', '  \"total\": 601,', '  \"HasAns_exact\": 74.92795389048992,', '  \"HasAns_f1\": 85.26053730664684,', '  \"HasAns_total\": 347,', '  \"NoAns_exact\": 93.30708661417323,', '  \"NoAns_f1\": 93.30708661417323,', '  \"NoAns_total\": 254,', '  \"best_exact\": 83.19467554076539,', '  \"best_exact_thresh\": -3.302623748779297,', '  \"best_f1\": 89.16041005891262,', '  \"best_f1_thresh\": -2.5785694122314453', '}']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtype</th>\n",
       "      <th>exact</th>\n",
       "      <th>f1</th>\n",
       "      <th>total</th>\n",
       "      <th>op_exact</th>\n",
       "      <th>op_f1</th>\n",
       "      <th>op_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Whitening</td>\n",
       "      <td>76.678445</td>\n",
       "      <td>86.999271</td>\n",
       "      <td>283</td>\n",
       "      <td>71.024735</td>\n",
       "      <td>81.083467</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Moisturization</td>\n",
       "      <td>82.695507</td>\n",
       "      <td>88.661242</td>\n",
       "      <td>601</td>\n",
       "      <td>79.367720</td>\n",
       "      <td>85.134400</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Irritation</td>\n",
       "      <td>81.674208</td>\n",
       "      <td>89.374608</td>\n",
       "      <td>442</td>\n",
       "      <td>77.375566</td>\n",
       "      <td>85.163971</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greasy</td>\n",
       "      <td>85.138004</td>\n",
       "      <td>91.509784</td>\n",
       "      <td>471</td>\n",
       "      <td>87.685775</td>\n",
       "      <td>91.819509</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smell</td>\n",
       "      <td>87.229437</td>\n",
       "      <td>93.254299</td>\n",
       "      <td>462</td>\n",
       "      <td>83.766234</td>\n",
       "      <td>88.198628</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fat Granule</td>\n",
       "      <td>96.153846</td>\n",
       "      <td>97.202797</td>\n",
       "      <td>26</td>\n",
       "      <td>57.692308</td>\n",
       "      <td>71.249178</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subtype      exact         f1  total   op_exact      op_f1  op_total\n",
       "0       Whitening  76.678445  86.999271    283  71.024735  81.083467       283\n",
       "5  Moisturization  82.695507  88.661242    601  79.367720  85.134400       601\n",
       "2      Irritation  81.674208  89.374608    442  77.375566  85.163971       442\n",
       "3          Greasy  85.138004  91.509784    471  87.685775  91.819509       471\n",
       "1           Smell  87.229437  93.254299    462  83.766234  88.198628       462\n",
       "4     Fat Granule  96.153846  97.202797     26  57.692308  71.249178        26"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# from utils_squad_multi_plus import read_ecom_examples as cc\n",
    "# from utils_squad_multi_plus import TRANS_SUBTYPE\n",
    "from utils_skincare import read_ecom_examples as cc\n",
    "from utils_skincare import TRANS_SUBTYPE\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "experiment_name = 'skincare_patch'\n",
    "runs_name = 'all_in_one_ground'\n",
    "run_name = f'{runs_name}/checkpoint-4200'  # 有时需要加上checkpoint后缀\n",
    "data_path = f'/data/projects/bert_pytorch/{experiment_name}'\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "ret = {}\n",
    "ret_op = {}\n",
    "ret_polar = {}\n",
    "\n",
    "dirlist = os.listdir(data_path)\n",
    "# dirlist = ['Moisturization']\n",
    "for filename in dirlist:\n",
    "    subtype = filename.replace('.','/').replace('_',\" \")\n",
    "    if subtype in TRANS_SUBTYPE:\n",
    "        try:\n",
    "            print(f'try to assess {subtype}')\n",
    "            temp = !python evaluate_ecom_asop.py -st aspect -sd skincare -rn {run_name} -tn {experiment_name} {filename} |tail -n 15\n",
    "            ret[subtype] = json.loads(''.join(temp))\n",
    "            temp = !python evaluate_ecom_asop.py -st op -sd skincare -rn {run_name} -tn {experiment_name}  {filename} |tail -n 15\n",
    "            ret_op[subtype] = json.loads(''.join(temp))\n",
    "#             temp = !python evaluate_ecom_asop.py -st polar  -sd skincare -rn {run_name} -tn {experiment_name} -pl {filename} |tail -n 15\n",
    "#             ret_polar[subtype] = json.loads(''.join(temp))\n",
    "        except Exception as e:\n",
    "            print('err', subtype, e)\n",
    "\n",
    "data = []     \n",
    "for k in ret.keys():\n",
    "    data.append(\n",
    "        (   k,\n",
    "            ret[k]['exact'], ret[k]['f1'], ret[k]['total'], \n",
    "            ret[k]['NoAns_exact'], ret[k]['NoAns_f1'],ret[k]['NoAns_total'], \n",
    "            ret_op[k]['exact'], ret_op[k]['f1'], ret_op[k]['total'], \n",
    "            ret_op[k]['NoAns_exact'], ret_op[k]['NoAns_f1'],ret_op[k]['NoAns_total'], \n",
    "#             ret_polar[k]['exact'], ret_polar[k]['f1'], ret_polar[k]['total'], \n",
    "#             ret_polar[k]['NoAns_exact'], ret_polar[k]['NoAns_f1'],ret_polar[k]['NoAns_total'], \n",
    "        )\n",
    "    )\n",
    "\n",
    "aspect_columns = ['exact','f1','total','NoAns_exact','NoAns_f1','NoAns_total']\n",
    "opinions_columns = list(map(lambda x: 'op_'+x, aspect_columns))\n",
    "polar_columns = list(map(lambda x: 'polar_'+x, aspect_columns))\n",
    "\n",
    "# df_metric = pd.DataFrame(data, columns =['subtype'] + aspect_columns+opinions_columns+polar_columns)\n",
    "df_metric = pd.DataFrame(data, columns =['subtype'] + aspect_columns+opinions_columns)\n",
    "\n",
    "df_metric.sort_values('f1', ascending=True, inplace=True)\n",
    "# df_metric.to_csv(os.path.join(data_path, 'metric_asop_mtl.csv'), index=False)\n",
    "# df_metric[['subtype','exact','f1','total', 'op_exact','op_f1','op_total', 'polar_exact','polar_f1','polar_total']]\n",
    "df_metric[['subtype','exact','f1','total', 'op_exact','op_f1','op_total']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T06:38:08.931271Z",
     "start_time": "2019-09-05T06:38:08.152322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Run: data=<RunData: metrics={'training_loss': 0.7133065998531203}, params={'learning_rate': '2e-05',\n",
       "  'max_seq_length': '256',\n",
       "  'num_train_epochs': '4.0',\n",
       "  'per_gpu_train_batch_size': '16',\n",
       "  'train_sample_ratio': '1.0'}, tags={'mlflow.runName': 'smell_1',\n",
       "  'mlflow.source.git.commit': '762abf82ce46134e12f8158697e92eed8bfef758',\n",
       "  'mlflow.source.name': '../examples/run_skincare_v2.py',\n",
       "  'mlflow.source.type': 'LOCAL',\n",
       "  'mlflow.user': 'ymai',\n",
       "  'output_dir': '/data/projects/bert_pytorch//skincare_op_out/smell_1'}>, info=<RunInfo: artifact_uri='/data/projects/mlruns/2/f6b60853a36946aea712116a42a17073/artifacts', end_time=1567661669252, experiment_id='2', lifecycle_stage='active', run_id='f6b60853a36946aea712116a42a17073', run_uuid='f6b60853a36946aea712116a42a17073', start_time=1567661398126, status='FINISHED', user_id='ymai'>>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 结果写入metric\n",
    "## 将加权F1写入mlflow文件\n",
    "import mlflow\n",
    "from  mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:9001')\n",
    "\n",
    "runs_name = 'smell_1'\n",
    "\n",
    "client = MlflowClient()\n",
    "experiments = client.list_experiments() # returns a list of mlflow.entities.Experiment\n",
    "experiment = list(filter(lambda x:x.name==experiment_name, experiments))\n",
    "target_run = client.search_runs(experiment[0].experiment_id, f\"tag.mlflow.runName='{runs_name}' and tag.mlflow.user='ymai'\")\n",
    "# if len(target_run) > 0:\n",
    "#     for _, line in df_metric.iterrows():\n",
    "#         sub = line['subtype']\n",
    "#         f1 = line['f1']\n",
    "#         op_f1 = line['op_f1']\n",
    "#         client.log_metric(target_run[0].info.run_id, f'{sub}_f1', f1)\n",
    "#         client.log_metric(target_run[0].info.run_id, f'{sub}_opf1', op_f1)\n",
    "#         print('write metric succeed...')\n",
    "target_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtype</th>\n",
       "      <th>exact</th>\n",
       "      <th>f1</th>\n",
       "      <th>op_exact</th>\n",
       "      <th>op_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Whitening</td>\n",
       "      <td>77.031802</td>\n",
       "      <td>86.613209</td>\n",
       "      <td>72.084806</td>\n",
       "      <td>82.009863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Irritation</td>\n",
       "      <td>79.864253</td>\n",
       "      <td>88.628954</td>\n",
       "      <td>77.828054</td>\n",
       "      <td>85.047052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Moisturization</td>\n",
       "      <td>83.693844</td>\n",
       "      <td>89.350809</td>\n",
       "      <td>80.698835</td>\n",
       "      <td>86.632476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greasy</td>\n",
       "      <td>84.925690</td>\n",
       "      <td>91.891473</td>\n",
       "      <td>88.959660</td>\n",
       "      <td>92.490295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smell</td>\n",
       "      <td>87.012987</td>\n",
       "      <td>93.065881</td>\n",
       "      <td>83.766234</td>\n",
       "      <td>89.098859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fat Granule</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>69.230769</td>\n",
       "      <td>76.752137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subtype       exact          f1   op_exact      op_f1\n",
       "5       Whitening   77.031802   86.613209  72.084806  82.009863\n",
       "2      Irritation   79.864253   88.628954  77.828054  85.047052\n",
       "0  Moisturization   83.693844   89.350809  80.698835  86.632476\n",
       "3          Greasy   84.925690   91.891473  88.959660  92.490295\n",
       "1           Smell   87.012987   93.065881  83.766234  89.098859\n",
       "4     Fat Granule  100.000000  100.000000  69.230769  76.752137"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ep5\n",
    "df_old = df_metric[['subtype','exact','f1','op_exact','op_f1']]\n",
    "df_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算指标（multi）\n",
    "各个subtype训练统一的阅读理解模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/data/projects/bert_pytorch/ecom_aspect_bak'\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas\n",
    "from utils_squad_op import TRANS_SUBTYPE\n",
    "\n",
    "ret = {}\n",
    "ret_op = {}\n",
    "\n",
    "for filename in os.listdir(data_path):\n",
    "    subtype = filename.replace('.','/').replace('_',\" \")\n",
    "    if subtype in TRANS_SUBTYPE:\n",
    "        try:\n",
    "            print(f'try to metric {subtype}')\n",
    "            temp = !python evaluate_ecom_v2.py -m -s {filename} all_in_one_nop |tail -n 15\n",
    "            ret[subtype] = json.loads(''.join(temp))\n",
    "#             temp = !python evaluate_ecom_v2.py -op -m -s {filename} all_in_one |tail -n 15\n",
    "#             ret_op[subtype] = json.loads(''.join(temp))\n",
    "        except:\n",
    "            print('err', subtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []     \n",
    "for k in ret.keys():\n",
    "    data.append(\n",
    "        (   k,\n",
    "            ret[k]['exact'], ret[k]['f1'], ret[k]['total'], \n",
    "            ret[k]['NoAns_exact'], ret[k]['NoAns_f1'],ret[k]['NoAns_total'], \n",
    "#             ret_op[k]['exact'], ret_op[k]['f1'], ret_op[k]['total'], \n",
    "#             ret_op[k]['NoAns_exact'], ret_op[k]['NoAns_f1'],ret_op[k]['NoAns_total'], \n",
    "        )\n",
    "    )\n",
    "\n",
    "aspect_columns = ['exact','f1','total','NoAns_exact','NoAns_f1','NoAns_total']\n",
    "opinions_columns = list(map(lambda x: 'op_'+x, aspect_columns))\n",
    "\n",
    "df_metric_all = pd.DataFrame(data, columns =['subtype'] + aspect_columns)\n",
    "df_metric_all.sort_values('exact', ascending=False, inplace=True)\n",
    "df_metric_all.to_csv(os.path.join(data_path, 'metric_as_all.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_metric_all.sort_values([ 'f1'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 两种指标具体差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path ='/data/projects/bert_pytorch/ecom_aspect_bak/raw_answer/'\n",
    "\n",
    "m = []\n",
    "with open(os.path.join(file_path, 'package_material_byall.json'), 'r') as f:\n",
    "    for line in f:\n",
    "        m.append(json.loads(line))\n",
    "        \n",
    "\n",
    "\n",
    "print(m[0])\n",
    "idx = 0 \n",
    "for k, v in m[1].items():\n",
    "    if v['label'] != \"\":\n",
    "        idx += 1\n",
    "        print(idx, v['text'])\n",
    "        label, pred = v['label'], v['pred']\n",
    "        print(f'<{label}>, <{pred}>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path ='/data/projects/bert_pytorch/ecom_aspect_bak/raw_answer/'\n",
    "\n",
    "m = []\n",
    "with open(os.path.join(file_path, 'package_material.json'), 'r') as f:\n",
    "    for line in f:\n",
    "        m.append(json.loads(line))\n",
    "        \n",
    "print(m[0])\n",
    "idx = 0 \n",
    "for k, v in m[1].items():\n",
    "    if v['label'] != \"\":\n",
    "        idx += 1\n",
    "        print(idx, v['text'])\n",
    "        label, pred = v['label'], v['pred']\n",
    "        print(f'<{label}>, <{pred}>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  NER 语料准备\n",
    "\n",
    "需要重新改写一下，所句子中出现的所有特征词，情感词统统找出来."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def find_positions(text, aspect_terms):    \n",
    "    ret = []\n",
    "    for term in aspect_terms:\n",
    "        re_exp = term.strip(' ').replace('  ', ' ').replace(' ', '.{0,20}?')\n",
    "        ret += [(i.start(), i.end()) for i in re.finditer(re_exp, text)]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "\n",
    "with open('/data/projects/bert_pytorch/ecom_aspect_bak/general.json', 'r') as c:\n",
    "    for line in c:\n",
    "        jl = json.loads(line)\n",
    "        text = jl['text']\n",
    "        pos = ['N'] * len(text)\n",
    "        for op in jl['opinions']:\n",
    "            ret = find_positions(text, op['aspectTerm'])\n",
    "            for start, end in ret:\n",
    "                if start != -2:\n",
    "                    for i in range(start, end):\n",
    "                        pos[i] = 'A'\n",
    "                    pos[start] = 'B-A'\n",
    "            ret = find_positions(text, op['opinionTerm'])\n",
    "            for start, end in ret:\n",
    "                if start != -2:\n",
    "                    for i in range(start, end):\n",
    "                        if pos[i] == 'N':\n",
    "                            pos[i] = 'A'\n",
    "                    if start == 0 or pos[start-1] == 'N':\n",
    "                        pos[start] = 'B-A'\n",
    "                        \n",
    "\n",
    "        raw_data.append({\n",
    "            'text': text,\n",
    "            'pos': pos,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "shuffle(raw_data)\n",
    "\n",
    "test_file  = '/home/aiuser/projects/changshuangkai/BERT-BER/data/ecom_v2/test_bio'\n",
    "train_file  = '/home/aiuser/projects/changshuangkai/BERT-BER/data/ecom_v2/train_bio'\n",
    "\n",
    "split = int(0.8*len(raw_data))\n",
    "train_raw_data = raw_data[:split]\n",
    "test_raw_data = raw_data[split:]\n",
    "\n",
    "def write_ner_data(file_path, data):\n",
    "    with open(file_path,'w') as c:\n",
    "        for i in data:\n",
    "            for token, tag in zip(i['text'], i['pos']):\n",
    "                c.write(f'{token} {tag}')\n",
    "                c.write('\\n')\n",
    "            c.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_ner_data(train_file, train_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_ner_data(test_file, test_raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多任务训练\n",
    "\n",
    "### 两个subtype的阅读理解一起训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/projects/bert_pytorch/ecom_aspect_mtl/'\n",
    "for dirname in os.listdir(data_dir):\n",
    "    subtype = dirname.replace('.','/').replace('_',\" \")\n",
    "    if subtype in TRANS_SUBTYPE:\n",
    "        print('eval', subtype)\n",
    "        !../script/run_ecom_multi_eval.sh {dirname}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 集成情感极性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 拆分情感极性数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils_skincare import find_positions\n",
    "from data_preprocess import convert_text\n",
    "\n",
    "json_path = '/data/projects/bert_pytorch/ecom_asop_mtl_opti_sample_v2/general.json'\n",
    "polar_corpus = []\n",
    "\n",
    "with open(json_path, 'r') as cc:\n",
    "    for line in cc:\n",
    "        jl = json.loads(line)\n",
    "        text = jl['text']\n",
    "        clear_text = convert_text(text)\n",
    "        for op in jl['opinions']:\n",
    "            start, end = find_positions(clear_text, op['opinionTerm'])\n",
    "            if start != -2:\n",
    "                subtype = op['aspectSubtype']\n",
    "                polar = op['polarity']\n",
    "                term = clear_text[start:end]\n",
    "                polar_corpus.append((term, clear_text, polar, subtype))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126035"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_polar = pd.DataFrame(polar_corpus ,columns=['opterm','textb','label','subtype'])\n",
    "len(df_polar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package_Material\n",
      "Package_Design\n",
      "Logistics_Speed\n",
      "Logistics_Package\n",
      "Wrong_Delivery\n",
      "Promotion\n",
      "WOM\n",
      "Price_Sensitivity\n",
      "Inventory\n",
      "Pick-up_Speed\n",
      "Package_Cleanliness\n",
      "Package_Printing\n",
      "New_User\n",
      "Package_Integrity\n",
      "Price_Satisfaction\n",
      "Logistics_Damage\n",
      "Brand_Equity\n",
      "Logistics_Fee\n",
      "Expiration_Date\n",
      "Return_Exchange\n",
      "Package_General\n",
      "Logistics_Service\n",
      "Logistics_Company\n",
      "Fake_Concern\n",
      "Loyalty\n",
      "Shop.Customer_Service\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from  utils_squad_multi_plus import TRANS_SUBTYPE\n",
    "ratio = 0.8\n",
    "corpus_dir = '/data/projects/bert_pytorch/ecom_asop_mtl_opti_sample_v2/'\n",
    "# corpus_dir = []\n",
    "for dirname in os.listdir(corpus_dir):\n",
    "    output_dir = os.path.join(corpus_dir, dirname)\n",
    "    subtype = dirname.replace('.', '/').replace('_',\" \")\n",
    "    if subtype not in TRANS_SUBTYPE:\n",
    "        continue\n",
    "    print(dirname)\n",
    "    temp  = df_polar[df_polar.subtype == subtype]\n",
    "    temp = temp.sample(frac=1)\n",
    "    train_limit = int(ratio * len(temp))\n",
    "    temp[:train_limit].to_csv(os.path.join(output_dir, 'train.csv'), index=False)\n",
    "    temp[train_limit:].to_csv(os.path.join(output_dir, 'dev.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "data_dir = '/data/projects/bert_pytorch/ecom_aspect_mtl_polar_out/'\n",
    "subtype = 'Return_Exchange'\n",
    "labels = []\n",
    "preds = []\n",
    "with open(os.path.join(data_dir, subtype, 'polarity_preds_.csv'), 'r') as c:\n",
    "    for line in c:\n",
    "        try:\n",
    "#             print(temp)\n",
    "            temp = line.strip('\\n').rsplit(',',6)\n",
    "            labels.append(temp[2])\n",
    "            preds.append(temp[3])\n",
    "        except:\n",
    "            pass\n",
    "          \n",
    "metric = precision_recall_fscore_support(labels, preds)\n",
    "pd.DataFrame(np.array(metric).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_squad_polar import read_ecom_examples, read_multi_examples\n",
    "\n",
    "data_dir = '/data/projects/bert_pytorch/ecom_aspect_mtl_polar/'\n",
    "\n",
    "ee = read_multi_examples(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取情感极性的F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 多任务训练结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T05:09:24.164927Z",
     "start_time": "2019-09-05T05:09:24.135108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smell\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "SUBTYPE_DICT = json.load(open('SUBTYPE.json', 'r'))\n",
    "TRANS_SUBTYPE = SUBTYPE_DICT['skincare']\n",
    "\n",
    "\n",
    "experiment_name = 'skincare_op'\n",
    "runs_name = 'smell_028'\n",
    "result_dir = f'/data/projects/bert_pytorch/{experiment_name}_out/{runs_name}'\n",
    "# result_dir = []\n",
    "\n",
    "polarity_map = {\n",
    "    0:1,\n",
    "    1:3,\n",
    "    2:5\n",
    "}\n",
    "\n",
    "polar_metric= []\n",
    "\n",
    "for dirname in os.listdir(result_dir):\n",
    "    output_dir = os.path.join(result_dir, dirname)\n",
    "    subtype = dirname.replace('.', '/').replace('_',\" \")\n",
    "    if subtype not in TRANS_SUBTYPE:\n",
    "        continue\n",
    "    print(subtype)\n",
    "    json_path = os.path.join(result_dir, dirname, 'eval_results.txt')\n",
    "    with open(json_path, 'r') as cc:\n",
    "        lines = cc.read().splitlines()\n",
    "        f1, prec, recall, support = [json.loads(item.split('=')[-1]) for item in lines[1:]]\n",
    "        for idx, m in enumerate(zip(f1, prec, recall, support)):  \n",
    "            polar_metric.append((\n",
    "                m[1], m[2], m[0], m[3], subtype, polarity_map[idx]\n",
    "            ))\n",
    "df_polar_m = pd.DataFrame(polar_metric, columns=['precision', 'recall', 'f1', 'sample_num', 'subtype', 'polarity'])\n",
    "df_polar_m['weight_f1'] = df_polar_m.apply(lambda x:x['sample_num']*x['f1'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T05:09:27.117143Z",
     "start_time": "2019-09-05T05:09:27.096069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9645776566757494, 0.9075630252100839)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 计算加权F1\n",
    "f1_pos = df_polar_m[df_polar_m.polarity==5]['weight_f1'].sum()/df_polar_m[df_polar_m.polarity==5]['sample_num'].sum()\n",
    "f1_neg = df_polar_m[df_polar_m.polarity==1]['weight_f1'].sum()/df_polar_m[df_polar_m.polarity==1]['sample_num'].sum()\n",
    "\n",
    "f1_pos, f1_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T05:09:29.416768Z",
     "start_time": "2019-09-05T05:09:28.688085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write metric succeed...\n"
     ]
    }
   ],
   "source": [
    "## 将加权F1写入mlflow文件\n",
    "import mlflow\n",
    "from  mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:9001')\n",
    "\n",
    "\n",
    "client = MlflowClient()\n",
    "experiments = client.list_experiments() # returns a list of mlflow.entities.Experiment\n",
    "experiment = list(filter(lambda x:x.name==experiment_name, experiments))\n",
    "target_run = client.search_runs(experiment[0].experiment_id, f\"tag.mlflow.runName='{runs_name}'\")\n",
    "\n",
    "if len(target_run) > 0:\n",
    "    client.log_metric(target_run[0].info.run_id, 'pos_polar_aver', f1_pos)\n",
    "    client.log_metric(target_run[0].info.run_id, 'neg_polar_aver', f1_neg)\n",
    "    print('write metric succeed...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ml_test_ep5/checkpoint-4200'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>sample_num</th>\n",
       "      <th>subtype</th>\n",
       "      <th>polarity</th>\n",
       "      <th>weight_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>7</td>\n",
       "      <td>Fat Granule</td>\n",
       "      <td>5</td>\n",
       "      <td>6.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>128</td>\n",
       "      <td>Irritation</td>\n",
       "      <td>5</td>\n",
       "      <td>122.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.952128</td>\n",
       "      <td>0.988950</td>\n",
       "      <td>0.970190</td>\n",
       "      <td>181</td>\n",
       "      <td>Smell</td>\n",
       "      <td>5</td>\n",
       "      <td>175.604336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.989362</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.978947</td>\n",
       "      <td>96</td>\n",
       "      <td>Whitening</td>\n",
       "      <td>5</td>\n",
       "      <td>93.978947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.983240</td>\n",
       "      <td>178</td>\n",
       "      <td>Greasy</td>\n",
       "      <td>5</td>\n",
       "      <td>175.016760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.984962</td>\n",
       "      <td>0.992424</td>\n",
       "      <td>0.988679</td>\n",
       "      <td>264</td>\n",
       "      <td>Moisturization</td>\n",
       "      <td>5</td>\n",
       "      <td>261.011321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    precision    recall        f1  sample_num         subtype  polarity  \\\n",
       "14   0.875000  1.000000  0.933333           7     Fat Granule         5   \n",
       "8    0.968000  0.945312  0.956522         128      Irritation         5   \n",
       "5    0.952128  0.988950  0.970190         181           Smell         5   \n",
       "17   0.989362  0.968750  0.978947          96       Whitening         5   \n",
       "11   0.977778  0.988764  0.983240         178          Greasy         5   \n",
       "2    0.984962  0.992424  0.988679         264  Moisturization         5   \n",
       "\n",
       "     weight_f1  \n",
       "14    6.533333  \n",
       "8   122.434783  \n",
       "5   175.604336  \n",
       "17   93.978947  \n",
       "11  175.016760  \n",
       "2   261.011321  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polar_m[df_polar_m.polarity==5].sort_values('f1', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polar_m.sort_values(by=['sample_num', 'subtype','polarity'], inplace=True)\n",
    "df_polar_m.to_csv('/data/projects/bert_pytorch/skincare_op/polar_metric_mtl.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 单一任务训练结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('/data/projects/bert_pytorch/ecom_output/label_3_polar/eval_raw.csv',header=None)\n",
    "df_corpus = pd.read_csv('/data/projects/bert_pytorch/ecom/label_3_polar/dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus['real'] = df_raw[1]\n",
    "df_corpus['pred'] = df_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "raws = []\n",
    "for k in TRANS_SUBTYPE.keys():\n",
    "#     print(k)\n",
    "    preds = df_corpus[df_corpus.subtype==k]['pred']\n",
    "    real = df_corpus[df_corpus.subtype==k]['real']\n",
    "    prec, recall, f1, support = precision_recall_fscore_support(real, preds)\n",
    "    for idx, metric in enumerate(zip(prec, recall, f1, support)):\n",
    "        raws.append((\n",
    "            *metric, k, polarity_map[idx]\n",
    "        ))\n",
    "df_polar_m1 = pd.DataFrame(raws, columns=['precision', 'recall', 'f1', 'sample_num', 'subtype', 'polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polar_m1.sort_values(by=['sample_num', 'subtype','polarity'], inplace=True)\n",
    "df_polar_m1.to_csv('/data/projects/bert_pytorch/ecom/label_3_polar/polar_metric.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polar_m1[df_polar_m1.polarity==1].sort_values('sample_num')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 极性预测详细结果生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name= 'skincare_op'\n",
    "runs_name = 'all_in_one/checkpoint-4200'\n",
    "\n",
    "label_map = {\n",
    "    1:3,\n",
    "    0:1,\n",
    "    2:5\n",
    "}\n",
    "polar_dir = os.path.join('/data/projects/bert_pytorch/', task_name)\n",
    "polar_out_dir = os.path.join('/data/projects/bert_pytorch/', f'{task_name}_out', runs_name)\n",
    "\n",
    "df_polar_raw = pd.DataFrame()\n",
    "for dirname in os.listdir(polar_dir):\n",
    "    subtype = dirname.replace('.', '/').replace('_',\" \")\n",
    "    if subtype not in TRANS_SUBTYPE:\n",
    "        continue \n",
    "    real_file = os.path.join(polar_dir, dirname,'dev.csv')\n",
    "    df_tmp = pd.read_csv(real_file)\n",
    "    \n",
    "    pred_file = os.path.join(polar_out_dir, dirname, 'eval_raw.csv')\n",
    "    df_temp_pred = pd.read_csv(pred_file, header=None)\n",
    "    df_tmp['predict'] = df_temp_pred[0].apply(lambda x: label_map[x])\n",
    "    df_polar_raw = pd.concat([df_polar_raw, df_tmp])\n",
    "    \n",
    "df_polar_raw.to_csv(os.path.join(polar_dir, 'polar_raw_results_0903.csv'), index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 滋润 {5: 68, 1: 1}\n",
      "1 还行 {5: 4, 1: 1}\n",
      "2 耐受 {5: 4, 1: 1}\n",
      "3 下去 {5: 1, 3: 1}\n",
      "4 不油 {5: 10, 1: 1}\n",
      "5 油腻 {1: 9, 5: 1}\n",
      "6 控油 {5: 4, 1: 1}\n",
      "共有情感词540, 其中存在极性冲突7, 占比1.2962962962962963\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "stat_op_confict = defaultdict(dict)\n",
    "\n",
    "for _, line in df_polar_raw.iterrows():\n",
    "    kw = line['opterm'] or 'null'\n",
    "    polar = line['predict'] or 'null'\n",
    "    stat_op_confict[kw][polar] = stat_op_confict[kw].get(polar,0)+1\n",
    "\n",
    "idx = 0\n",
    "for k, v in stat_op_confict.items():\n",
    "    total = sum(v.values())\n",
    "#     for i,j in v.items():\n",
    "#         v[i] = round(j/total*100,3)\n",
    "    if len(v) > 1:\n",
    "        print(idx,k,v)\n",
    "        idx+=1\n",
    "print(f'共有情感词{len(stat_op_confict)}, 其中存在极性冲突{idx}, 占比{idx/len(stat_op_confict)*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### span extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T10:44:15.020935Z",
     "start_time": "2019-09-06T10:44:15.011040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(3,10)\n",
    "x.size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取runs 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T02:42:38.293726Z",
     "start_time": "2019-09-06T02:42:38.278475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.28180354267310787, 0.5824915824915825)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_density_dict = defaultdict(dict)\n",
    "train_op_density_dict = defaultdict(dict)\n",
    "for fea in feas:\n",
    "    if fea.is_impossible == False:\n",
    "        asp_word =''.join(fea.tokens[fea.start_position:fea.end_position+1])\n",
    "        train_density_dict['kk'][asp_word] = train_density_dict['kk'].get(asp_word,0) + 1\n",
    "    if fea.is_op_impossible == False:\n",
    "        op_word=''.join(fea.tokens[fea.op_start_position:fea.op_end_position+1])\n",
    "        train_op_density_dict['kk'][op_word] =train_op_density_dict['kk'].get(op_word,0) + 1\n",
    "\n",
    "dens=len(train_density_dict['kk'])/sum(list(train_density_dict['kk'].values()))\n",
    "op_dens=len(train_op_density_dict['kk'])/sum(list(train_op_density_dict['kk'].values()))\n",
    "dens, op_dens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计语料密度\n",
    "- 各个subtype 关键词数n_kw和语料条数n的关系，用来衡量一个subtype的复杂度\n",
    "> 初步的猜想是希望 \n",
    "> - n_kw/n越小越好, 说明有充分语料信息来学习？？\n",
    "> - 不同的语料密度对训练数据量的要求是一致的吗？？\n",
    "\n",
    "\n",
    "- 随着采样的进行，高频词更容易被踩到，这样此时词语变得更加分散了，密度提升了。 \n",
    "- 标注的过程正好相反，是一个密度降低的过程\n",
    "    - 新词出现本身是一个快到慢的过程，意味着密度是可以逐渐下降的，那么何时收敛\n",
    "    - 新词出现速度和样本量增长达到稳态了\n",
    "- 密度越小测试集指标一定会不断提升吗？\n",
    "    - 还有一个判定非相关的问题。\n",
    "\n",
    "\n",
    "### skincare语料统计\n",
    "\n",
    "- **Moisturization**\n",
    "{'语料大小': 1268, '情感词': 311, '特征词': 137, '冲突词': 0, '情感密度': 0.24526813880126183, '特征密度': 0.10804416403785488}\n",
    "- **Smell**\n",
    "{'语料大小': 974, '情感词': 273, '特征词': 157, '冲突词': 0, '情感密度': 0.2802874743326489, '特征密度': 0.16119096509240247}\n",
    "- **Irritation**\n",
    "{'语料大小': 930, '情感词': 336, '特征词': 131, '冲突词': 0, '情感密度': 0.36129032258064514, '特征密度': 0.14086021505376345}\n",
    "- **Greasy**\n",
    "{'语料大小': 1008, '情感词': 251, '特征词': 146, '冲突词': 0, '情感密度': 0.2490079365079365, '特征密度': 0.14484126984126985}\n",
    "- **Fat Granule**\n",
    "{'语料大小': 53, '情感词': 39, '特征词': 3, '冲突词': 0, '情感密度': 0.7358490566037735, '特征密度': 0.05660377358490566}\n",
    "- **Whitening**\n",
    "{'语料大小': 587, '情感词': 362, '特征词': 159, '冲突词': 0, '情感密度': 0.616695059625213, '特征密度': 0.2708688245315162}\n",
    "---\n",
    "- 情感有难到易\n",
    "['Fat Granule', 'Whitening', 'Irritation', 'Smell', 'Greasy', 'Moisturization']\n",
    "- 特征有难到易\n",
    "['Whitening', 'Smell', 'Greasy', 'Irritation', 'Moisturization', 'Fat Granule']\n",
    "\n",
    "### general语料统计\n",
    "\n",
    "- **Package Material**\n",
    "{'语料大小': 48, '情感词': 45, '特征词': 17, '冲突词': 0, '情感密度': 0.9375, '特征密度': 0.3541666666666667}\n",
    "- **Package Design**\n",
    "{'语料大小': 2677, '情感词': 543, '特征词': 456, '冲突词': 0, '情感密度': 0.20283899887934254, '特征密度': 0.17033993276055287}\n",
    "- **Logistics Speed**\n",
    "{'语料大小': 7825, '情感词': 1340, '特征词': 1065, '冲突词': 0, '情感密度': 0.17124600638977636, '特征密度': 0.13610223642172525}\n",
    "- **Logistics Package**\n",
    "{'语料大小': 5483, '情感词': 1186, '特征词': 876, '冲突词': 0, '情感密度': 0.21630494254969906, '特征密度': 0.1597665511581251}\n",
    "- **Wrong Delivery**\n",
    "{'语料大小': 1016, '情感词': 375, '特征词': 259, '冲突词': 0, '情感密度': 0.3690944881889764, '特征密度': 0.2549212598425197}\n",
    "- **Promotion**\n",
    "{'语料大小': 10239, '情感词': 3056, '特征词': 857, '冲突词': 0, '情感密度': 0.2984666471335091, '特征密度': 0.083699580037113}\n",
    "- **WOM**\n",
    "{'语料大小': 996, '情感词': 52, '特征词': 111, '冲突词': 0, '情感密度': 0.05220883534136546, '特征密度': 0.11144578313253012}\n",
    "- **Price Sensitivity**\n",
    "{'语料大小': 3956, '情感词': 656, '特征词': 336, '冲突词': 1, '情感密度': 0.16582406471183014, '特征密度': 0.08493427704752275}\n",
    "- **Inventory**\n",
    "{'语料大小': 430, '情感词': 98, '特征词': 25, '冲突词': 0, '情感密度': 0.22790697674418606, '特征密度': 0.05813953488372093}\n",
    "- **Pick-up Speed**\n",
    "{'语料大小': 2939, '情感词': 486, '特征词': 248, '冲突词': 0, '情感密度': 0.1653623681524328, '特征密度': 0.0843824430078258}\n",
    "- **Package Cleanliness**\n",
    "{'语料大小': 440, '情感词': 121, '特征词': 252, '冲突词': 0, '情感密度': 0.275, '特征密度': 0.5727272727272728}\n",
    "- **Package Printing**\n",
    "{'语料大小': 61, '情感词': 46, '特征词': 39, '冲突词': 0, '情感密度': 0.7540983606557377, '特征密度': 0.639344262295082}\n",
    "- **New User**\n",
    "{'语料大小': 1071, '情感词': 416, '特征词': 77, '冲突词': 0, '情感密度': 0.388422035480859, '特征密度': 0.0718954248366013}\n",
    "- **Package Integrity**\n",
    "{'语料大小': 2111, '情感词': 323, '特征词': 641, '冲突词': 0, '情感密度': 0.15300805305542398, '特征密度': 0.3036475603979157}\n",
    "- **Price Satisfaction**\n",
    "{'语料大小': 12180, '情感词': 1366, '特征词': 371, '冲突词': 1, '情感密度': 0.11215106732348111, '特征密度': 0.03045977011494253}\n",
    "- **Logistics Damage**\n",
    "{'语料大小': 5292, '情感词': 650, '特征词': 1108, '冲突词': 0, '情感密度': 0.12282690854119425, '特征密度': 0.20937263794406652}\n",
    "- **Brand Equity**\n",
    "{'语料大小': 5406, '情感词': 1755, '特征词': 189, '冲突词': 0, '情感密度': 0.3246392896781354, '特征密度': 0.03496115427302997}\n",
    "- **Logistics Fee**\n",
    "{'语料大小': 1053, '情感词': 516, '特征词': 123, '冲突词': 1, '情感密度': 0.49002849002849, '特征密度': 0.1168091168091168}\n",
    "- **Expiration Date**\n",
    "{'语料大小': 2265, '情感词': 534, '特征词': 233, '冲突词': 0, '情感密度': 0.23576158940397351, '特征密度': 0.10286975717439294}\n",
    "- **Return Exchange**\n",
    "{'语料大小': 1447, '情感词': 754, '特征词': 112, '冲突词': 0, '情感密度': 0.5210780926053905, '特征密度': 0.07740152038700761}\n",
    "- **Package General**\n",
    "{'语料大小': 1825, '情感词': 632, '特征词': 600, '冲突词': 0, '情感密度': 0.3463013698630137, '特征密度': 0.3287671232876712}\n",
    "- **Logistics Service**\n",
    "{'语料大小': 5376, '情感词': 1330, '特征词': 1019, '冲突词': 0, '情感密度': 0.24739583333333334, '特征密度': 0.18954613095238096}\n",
    "- **Logistics Company**\n",
    "{'语料大小': 1403, '情感词': 421, '特征词': 36, '冲突词': 0, '情感密度': 0.3000712758374911, '特征密度': 0.02565930149679259}\n",
    "- **Fake Concern**\n",
    "{'语料大小': 5619, '情感词': 1614, '特征词': 784, '冲突词': 1, '情感密度': 0.2872397223705286, '特征密度': 0.1395266061576793}\n",
    "- **Loyalty**\n",
    "{'语料大小': 13088, '情感词': 2563, '特征词': 1456, '冲突词': 0, '情感密度': 0.19582823960880197, '特征密度': 0.11124694376528117}\n",
    "- **Shop/Customer Service**\n",
    "{'语料大小': 6574, '情感词': 2403, '特征词': 1908, '冲突词': 0, '情感密度': 0.36553087922117433, '特征密度': 0.2902342561606328}\n",
    "---\n",
    "- 情感有难到易\n",
    "['Package Material', 'Package Printing', 'Return Exchange', 'Logistics Fee', 'New User', 'Wrong Delivery', 'Shop/Customer Service', 'Package General', 'Brand Equity', 'Logistics Company', 'Promotion', 'Fake Concern', 'Package Cleanliness', 'Logistics Service', 'Expiration Date', 'Inventory', 'Logistics Package', 'Package Design', 'Loyalty', 'Logistics Speed', 'Price Sensitivity', 'Pick-up Speed', 'Package Integrity', 'Logistics Damage', 'Price Satisfaction', 'WOM']\n",
    "- 特征有难到易\n",
    "['Package Printing', 'Package Cleanliness', 'Package Material', 'Package General', 'Package Integrity', 'Shop/Customer Service', 'Wrong Delivery', 'Logistics Damage', 'Logistics Service', 'Package Design', 'Logistics Package', 'Fake Concern', 'Logistics Speed', 'Logistics Fee', 'WOM', 'Loyalty', 'Expiration Date', 'Price Sensitivity', 'Pick-up Speed', 'Promotion', 'Return Exchange', 'New User', 'Inventory', 'Brand Equity', 'Price Satisfaction', 'Logistics Company']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T09:08:22.699744Z",
     "start_time": "2019-09-12T09:08:22.656599Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils_squad_multi_plus import TRANS_SUBTYPE\n",
    "# from utils_skincare import TRANS_SUBTYPE\n",
    "\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "experiment_name = 'ecom_asop_mtl_opti_sample_v2'\n",
    "# runs_name = 'smell_1'\n",
    "# run_name = f'{runs_name}'  # 有时需要加上checkpoint后缀\n",
    "data_path = f'/data/projects/bert_pytorch/{experiment_name}'\n",
    "frac=0.85\n",
    "\n",
    "\n",
    "def generate_corpus_stats(experiment_name, data_path, sublist=TRANS_SUBTYPE, frac=1, verbose=False):\n",
    "    corpus_stats = defaultdict(dict)\n",
    "    for dirname in os.listdir(data_path):\n",
    "        subtype = dirname.replace('.','/').replace('_',\" \")\n",
    "        if subtype not in sublist:\n",
    "            continue\n",
    "\n",
    "        stat_op_confict = defaultdict(dict)\n",
    "        stat_asp = set()\n",
    "        df_temp_raw = pd.read_csv(os.path.join(data_path, dirname,'dev.csv'))\n",
    "        df_temp_raw = df_temp_raw.sample(frac=frac)\n",
    "\n",
    "        idx = 0\n",
    "        train_json_path = os.path.join(data_path, dirname, 'dev.json')\n",
    "        train_num = !wc -l {train_json_path}\n",
    "        threshold = int(frac * int(train_num[0].split()[0]))\n",
    "#         print(threshold)\n",
    "\n",
    "        with open(train_json_path, 'r') as c:\n",
    "            for line in c:\n",
    "                if random.randint(0,1000) > 1000 * frac:\n",
    "                    continue\n",
    "#                 idx += 1\n",
    "#                 if idx > threshold: break\n",
    "                jl = json.loads(line)\n",
    "                for op in jl['opinions']:\n",
    "                    if op['aspectSubtype'] == subtype:\n",
    "                        stat_asp.add(op['aspectTerm'][0])\n",
    "        print(subtype, stat_asp)\n",
    "\n",
    "        for _, line in df_temp_raw.iterrows():\n",
    "            kw = line['opterm'] or 'null'\n",
    "            polar = line['label'] or 'null'\n",
    "            stat_op_confict[kw][polar] = stat_op_confict[kw].get(polar,0)+1\n",
    "\n",
    "        idx = 0\n",
    "        print('打印冲突词', subtype)\n",
    "        for k, v in stat_op_confict.items():\n",
    "            total = sum(v.values())\n",
    "\n",
    "            if len(v) > 1:\n",
    "                print(idx,k,v)\n",
    "                idx+=1\n",
    "        corpus_stats[subtype].update({\n",
    "            'total': len(df_temp_raw),\n",
    "            'opinion': len(stat_op_confict),\n",
    "            'aspect': len(stat_asp),\n",
    "            'conflict': idx,\n",
    "            'op_den': len(stat_op_confict)/len(df_temp_raw),\n",
    "            'asp_den': len(stat_asp)/len(df_temp_raw),\n",
    "        })\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        for k, v in corpus_stats.items():\n",
    "            print(f'**{k}**')\n",
    "            print(v['asp_den'],v['op_den'])\n",
    "\n",
    "        print('情感有难到易')\n",
    "        print(sorted(corpus_stats, key=lambda x: corpus_stats[x]['op_den'], reverse=True))\n",
    "        print('特征有难到易')\n",
    "        print(sorted(corpus_stats, key=lambda x: corpus_stats[x]['asp_den'], reverse=True))\n",
    "    return corpus_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T02:05:57.044353Z",
     "start_time": "2019-09-06T02:00:09.280755Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 补了邮费 {5: 1, 1: 1}\n",
      "0 再优惠点就好 {3: 1, 1: 1}\n",
      "0 和之前不太一样 {1: 1, 5: 1}\n",
      "0 补了邮费 {1: 1, 5: 1}\n",
      "0 和超市价格差不多 {3: 1, 5: 1}\n",
      "0 再优惠点就好 {3: 1, 1: 1}\n",
      "0 和之前不太一样 {5: 1, 1: 1}\n",
      "0 和超市价格差不多 {3: 1, 5: 1}\n",
      "0 和之前不太一样 {5: 1, 1: 1}\n",
      "0 补了邮费 {1: 1, 5: 1}\n",
      "0 和超市价格差不多 {3: 1, 5: 1}\n",
      "0 补了邮费 {1: 1, 5: 1}\n",
      "0 和超市价格差不多 {3: 1, 5: 1}\n",
      "0 再优惠点就好 {3: 1, 1: 1}\n",
      "0 和之前不太一样 {1: 1, 5: 1}\n",
      "0 和超市价格差不多 {3: 1, 5: 1}\n",
      "0 补了邮费 {5: 1, 1: 1}\n",
      "0 再优惠点就好 {3: 1, 1: 1}\n",
      "0 和之前不太一样 {1: 1, 5: 1}\n",
      "0 和超市价格差不多 {5: 2, 3: 1}\n",
      "0 补了邮费 {1: 1, 5: 1}\n",
      "0 再优惠点就好 {3: 1, 1: 1}\n",
      "0 和之前不太一样 {1: 1, 5: 1}\n",
      "0 和超市价格差不多 {5: 1, 3: 1}\n",
      "0 补了邮费 {1: 1, 5: 1}\n",
      "0 和之前不太一样 {5: 1, 1: 1}\n",
      "0 和超市价格差不多 {5: 2, 3: 1}\n",
      "0 补了邮费 {5: 1, 1: 1}\n",
      "0 再优惠点就好 {1: 1, 3: 1}\n",
      "0 和之前不太一样 {5: 1, 1: 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>Package Cleanliness_den</th>\n",
       "      <th>Package Cleanliness_op_den</th>\n",
       "      <th>Package Material_den</th>\n",
       "      <th>Package Material_op_den</th>\n",
       "      <th>Price Sensitivity_den</th>\n",
       "      <th>Price Sensitivity_op_den</th>\n",
       "      <th>Package Printing_den</th>\n",
       "      <th>Package Printing_op_den</th>\n",
       "      <th>Package Integrity_den</th>\n",
       "      <th>...</th>\n",
       "      <th>Wrong Delivery_den</th>\n",
       "      <th>Wrong Delivery_op_den</th>\n",
       "      <th>Price Satisfaction_den</th>\n",
       "      <th>Price Satisfaction_op_den</th>\n",
       "      <th>Fake Concern_den</th>\n",
       "      <th>Fake Concern_op_den</th>\n",
       "      <th>Brand Equity_den</th>\n",
       "      <th>Brand Equity_op_den</th>\n",
       "      <th>Logistics Service_den</th>\n",
       "      <th>Logistics Service_op_den</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.184343</td>\n",
       "      <td>0.287879</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.540284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.091133</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.339858</td>\n",
       "      <td>0.464413</td>\n",
       "      <td>0.157116</td>\n",
       "      <td>0.521257</td>\n",
       "      <td>0.423792</td>\n",
       "      <td>0.434944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.175379</td>\n",
       "      <td>0.231029</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.184455</td>\n",
       "      <td>0.262159</td>\n",
       "      <td>0.417556</td>\n",
       "      <td>0.127004</td>\n",
       "      <td>0.489519</td>\n",
       "      <td>0.336228</td>\n",
       "      <td>0.393300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.155499</td>\n",
       "      <td>0.232617</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.521327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.512315</td>\n",
       "      <td>0.064450</td>\n",
       "      <td>0.177750</td>\n",
       "      <td>0.251779</td>\n",
       "      <td>0.420819</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.448659</td>\n",
       "      <td>0.322791</td>\n",
       "      <td>0.381395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.149646</td>\n",
       "      <td>0.240647</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330709</td>\n",
       "      <td>0.484252</td>\n",
       "      <td>0.059442</td>\n",
       "      <td>0.158949</td>\n",
       "      <td>0.226335</td>\n",
       "      <td>0.383630</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>0.434172</td>\n",
       "      <td>0.308780</td>\n",
       "      <td>0.351190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.689394</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.147430</td>\n",
       "      <td>0.213985</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.470774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.472131</td>\n",
       "      <td>0.052819</td>\n",
       "      <td>0.154078</td>\n",
       "      <td>0.212930</td>\n",
       "      <td>0.370107</td>\n",
       "      <td>0.079531</td>\n",
       "      <td>0.402589</td>\n",
       "      <td>0.293862</td>\n",
       "      <td>0.343459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.720779</td>\n",
       "      <td>0.370130</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.126354</td>\n",
       "      <td>0.215162</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.424899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351124</td>\n",
       "      <td>0.469101</td>\n",
       "      <td>0.050903</td>\n",
       "      <td>0.143092</td>\n",
       "      <td>0.214032</td>\n",
       "      <td>0.357905</td>\n",
       "      <td>0.071882</td>\n",
       "      <td>0.395877</td>\n",
       "      <td>0.277365</td>\n",
       "      <td>0.325717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.738636</td>\n",
       "      <td>0.346591</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.123262</td>\n",
       "      <td>0.193426</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.433649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312808</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.050903</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.213078</td>\n",
       "      <td>0.352313</td>\n",
       "      <td>0.064755</td>\n",
       "      <td>0.386679</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.312558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111236</td>\n",
       "      <td>0.196067</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.384211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304158</td>\n",
       "      <td>0.402626</td>\n",
       "      <td>0.046707</td>\n",
       "      <td>0.138113</td>\n",
       "      <td>0.194543</td>\n",
       "      <td>0.347568</td>\n",
       "      <td>0.058364</td>\n",
       "      <td>0.376079</td>\n",
       "      <td>0.255891</td>\n",
       "      <td>0.301364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109201</td>\n",
       "      <td>0.183013</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.376894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332677</td>\n",
       "      <td>0.456693</td>\n",
       "      <td>0.042693</td>\n",
       "      <td>0.130870</td>\n",
       "      <td>0.180071</td>\n",
       "      <td>0.332740</td>\n",
       "      <td>0.056974</td>\n",
       "      <td>0.365520</td>\n",
       "      <td>0.236607</td>\n",
       "      <td>0.289062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.607438</td>\n",
       "      <td>0.338843</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.104320</td>\n",
       "      <td>0.179228</td>\n",
       "      <td>1.029412</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.367786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313059</td>\n",
       "      <td>0.436494</td>\n",
       "      <td>0.039857</td>\n",
       "      <td>0.130467</td>\n",
       "      <td>0.180583</td>\n",
       "      <td>0.321683</td>\n",
       "      <td>0.050118</td>\n",
       "      <td>0.356542</td>\n",
       "      <td>0.229625</td>\n",
       "      <td>0.280352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.632576</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100674</td>\n",
       "      <td>0.188290</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.348066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.419672</td>\n",
       "      <td>0.038451</td>\n",
       "      <td>0.126847</td>\n",
       "      <td>0.167606</td>\n",
       "      <td>0.321566</td>\n",
       "      <td>0.050247</td>\n",
       "      <td>0.369297</td>\n",
       "      <td>0.232176</td>\n",
       "      <td>0.282393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.618881</td>\n",
       "      <td>0.328671</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.095294</td>\n",
       "      <td>0.181641</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.357872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280303</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.037135</td>\n",
       "      <td>0.124163</td>\n",
       "      <td>0.164841</td>\n",
       "      <td>0.314348</td>\n",
       "      <td>0.046955</td>\n",
       "      <td>0.350028</td>\n",
       "      <td>0.219233</td>\n",
       "      <td>0.269319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.288961</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.100397</td>\n",
       "      <td>0.180932</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.341678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285513</td>\n",
       "      <td>0.406470</td>\n",
       "      <td>0.034952</td>\n",
       "      <td>0.122684</td>\n",
       "      <td>0.160437</td>\n",
       "      <td>0.309942</td>\n",
       "      <td>0.044662</td>\n",
       "      <td>0.352801</td>\n",
       "      <td>0.214722</td>\n",
       "      <td>0.273186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.296970</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.094708</td>\n",
       "      <td>0.176272</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.334807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274278</td>\n",
       "      <td>0.389764</td>\n",
       "      <td>0.035359</td>\n",
       "      <td>0.122167</td>\n",
       "      <td>0.159468</td>\n",
       "      <td>0.308258</td>\n",
       "      <td>0.041687</td>\n",
       "      <td>0.351998</td>\n",
       "      <td>0.209821</td>\n",
       "      <td>0.266369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.275568</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.093523</td>\n",
       "      <td>0.173460</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.326229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285363</td>\n",
       "      <td>0.391144</td>\n",
       "      <td>0.035099</td>\n",
       "      <td>0.118432</td>\n",
       "      <td>0.154839</td>\n",
       "      <td>0.303226</td>\n",
       "      <td>0.041618</td>\n",
       "      <td>0.339191</td>\n",
       "      <td>0.207859</td>\n",
       "      <td>0.260405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.286096</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.088314</td>\n",
       "      <td>0.171870</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.317726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275463</td>\n",
       "      <td>0.372685</td>\n",
       "      <td>0.032841</td>\n",
       "      <td>0.116971</td>\n",
       "      <td>0.150335</td>\n",
       "      <td>0.295645</td>\n",
       "      <td>0.039173</td>\n",
       "      <td>0.334929</td>\n",
       "      <td>0.200656</td>\n",
       "      <td>0.257768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.285354</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.089045</td>\n",
       "      <td>0.168820</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.312105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258206</td>\n",
       "      <td>0.366521</td>\n",
       "      <td>0.032111</td>\n",
       "      <td>0.114760</td>\n",
       "      <td>0.146530</td>\n",
       "      <td>0.289104</td>\n",
       "      <td>0.037410</td>\n",
       "      <td>0.331141</td>\n",
       "      <td>0.196362</td>\n",
       "      <td>0.251964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.583732</td>\n",
       "      <td>0.275120</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.086216</td>\n",
       "      <td>0.167908</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.311222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262176</td>\n",
       "      <td>0.376166</td>\n",
       "      <td>0.031199</td>\n",
       "      <td>0.113819</td>\n",
       "      <td>0.142937</td>\n",
       "      <td>0.289060</td>\n",
       "      <td>0.036020</td>\n",
       "      <td>0.329829</td>\n",
       "      <td>0.194047</td>\n",
       "      <td>0.249853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.572727</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.084934</td>\n",
       "      <td>0.165824</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.303648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254921</td>\n",
       "      <td>0.369094</td>\n",
       "      <td>0.030460</td>\n",
       "      <td>0.112151</td>\n",
       "      <td>0.139527</td>\n",
       "      <td>0.287240</td>\n",
       "      <td>0.034961</td>\n",
       "      <td>0.324639</td>\n",
       "      <td>0.189546</td>\n",
       "      <td>0.247396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1.0  Package Cleanliness_den  Package Cleanliness_op_den  \\\n",
       "0   0.10                 0.727273                    0.477273   \n",
       "1   0.15                 0.772727                    0.545455   \n",
       "2   0.20                 0.625000                    0.397727   \n",
       "3   0.25                 0.709091                    0.427273   \n",
       "4   0.30                 0.689394                    0.386364   \n",
       "5   0.35                 0.720779                    0.370130   \n",
       "6   0.40                 0.738636                    0.346591   \n",
       "7   0.45                 0.737374                    0.378788   \n",
       "8   0.50                 0.654545                    0.309091   \n",
       "9   0.55                 0.607438                    0.338843   \n",
       "10  0.60                 0.632576                    0.340909   \n",
       "11  0.65                 0.618881                    0.328671   \n",
       "12  0.70                 0.642857                    0.288961   \n",
       "13  0.75                 0.636364                    0.296970   \n",
       "14  0.80                 0.602273                    0.275568   \n",
       "15  0.85                 0.590909                    0.286096   \n",
       "16  0.90                 0.590909                    0.285354   \n",
       "17  0.95                 0.583732                    0.275120   \n",
       "18  1.00                 0.572727                    0.275000   \n",
       "\n",
       "    Package Material_den  Package Material_op_den  Price Sensitivity_den  \\\n",
       "0               1.800000                 1.000000               0.184343   \n",
       "1               1.571429                 1.000000               0.175379   \n",
       "2               0.900000                 1.000000               0.155499   \n",
       "3               1.083333                 1.000000               0.149646   \n",
       "4               1.142857                 1.000000               0.147430   \n",
       "5               0.705882                 0.941176               0.126354   \n",
       "6               0.842105                 0.947368               0.123262   \n",
       "7               0.681818                 1.000000               0.111236   \n",
       "8               0.708333                 1.000000               0.109201   \n",
       "9               0.615385                 1.000000               0.104320   \n",
       "10              0.586207                 1.000000               0.100674   \n",
       "11              0.548387                 0.935484               0.095294   \n",
       "12              0.470588                 0.941176               0.100397   \n",
       "13              0.472222                 0.944444               0.094708   \n",
       "14              0.447368                 0.947368               0.093523   \n",
       "15              0.414634                 0.951220               0.088314   \n",
       "16              0.395349                 0.930233               0.089045   \n",
       "17              0.369565                 0.934783               0.086216   \n",
       "18              0.354167                 0.937500               0.084934   \n",
       "\n",
       "    Price Sensitivity_op_den  Package Printing_den  Package Printing_op_den  \\\n",
       "0                   0.287879              2.333333                 0.666667   \n",
       "1                   0.231029              2.000000                 0.666667   \n",
       "2                   0.232617              1.666667                 0.916667   \n",
       "3                   0.240647              1.533333                 0.866667   \n",
       "4                   0.213985              1.500000                 0.777778   \n",
       "5                   0.215162              1.571429                 0.857143   \n",
       "6                   0.193426              1.166667                 0.916667   \n",
       "7                   0.196067              1.222222                 0.851852   \n",
       "8                   0.183013              1.166667                 0.866667   \n",
       "9                   0.179228              1.029412                 0.705882   \n",
       "10                  0.188290              0.972973                 0.837838   \n",
       "11                  0.181641              0.975000                 0.850000   \n",
       "12                  0.180932              0.883721                 0.813953   \n",
       "13                  0.176272              0.847826                 0.782609   \n",
       "14                  0.173460              0.795918                 0.775510   \n",
       "15                  0.171870              0.750000                 0.788462   \n",
       "16                  0.168820              0.709091                 0.781818   \n",
       "17                  0.167908              0.672414                 0.758621   \n",
       "18                  0.165824              0.639344                 0.754098   \n",
       "\n",
       "    Package Integrity_den  ...  Wrong Delivery_den  Wrong Delivery_op_den  \\\n",
       "0                0.540284  ...            0.450980               0.617647   \n",
       "1                0.555205  ...            0.394737               0.565789   \n",
       "2                0.521327  ...            0.413793               0.512315   \n",
       "3                0.431818  ...            0.330709               0.484252   \n",
       "4                0.470774  ...            0.363934               0.472131   \n",
       "5                0.424899  ...            0.351124               0.469101   \n",
       "6                0.433649  ...            0.312808               0.431034   \n",
       "7                0.384211  ...            0.304158               0.402626   \n",
       "8                0.376894  ...            0.332677               0.456693   \n",
       "9                0.367786  ...            0.313059               0.436494   \n",
       "10               0.348066  ...            0.278689               0.419672   \n",
       "11               0.357872  ...            0.280303               0.416667   \n",
       "12               0.341678  ...            0.285513               0.406470   \n",
       "13               0.334807  ...            0.274278               0.389764   \n",
       "14               0.326229  ...            0.285363               0.391144   \n",
       "15               0.317726  ...            0.275463               0.372685   \n",
       "16               0.312105  ...            0.258206               0.366521   \n",
       "17               0.311222  ...            0.262176               0.376166   \n",
       "18               0.303648  ...            0.254921               0.369094   \n",
       "\n",
       "    Price Satisfaction_den  Price Satisfaction_op_den  Fake Concern_den  \\\n",
       "0                 0.091133                   0.214286          0.339858   \n",
       "1                 0.079365                   0.184455          0.262159   \n",
       "2                 0.064450                   0.177750          0.251779   \n",
       "3                 0.059442                   0.158949          0.226335   \n",
       "4                 0.052819                   0.154078          0.212930   \n",
       "5                 0.050903                   0.143092          0.214032   \n",
       "6                 0.050903                   0.137931          0.213078   \n",
       "7                 0.046707                   0.138113          0.194543   \n",
       "8                 0.042693                   0.130870          0.180071   \n",
       "9                 0.039857                   0.130467          0.180583   \n",
       "10                0.038451                   0.126847          0.167606   \n",
       "11                0.037135                   0.124163          0.164841   \n",
       "12                0.034952                   0.122684          0.160437   \n",
       "13                0.035359                   0.122167          0.159468   \n",
       "14                0.035099                   0.118432          0.154839   \n",
       "15                0.032841                   0.116971          0.150335   \n",
       "16                0.032111                   0.114760          0.146530   \n",
       "17                0.031199                   0.113819          0.142937   \n",
       "18                0.030460                   0.112151          0.139527   \n",
       "\n",
       "    Fake Concern_op_den  Brand Equity_den  Brand Equity_op_den  \\\n",
       "0              0.464413          0.157116             0.521257   \n",
       "1              0.417556          0.127004             0.489519   \n",
       "2              0.420819          0.106383             0.448659   \n",
       "3              0.383630          0.088757             0.434172   \n",
       "4              0.370107          0.079531             0.402589   \n",
       "5              0.357905          0.071882             0.395877   \n",
       "6              0.352313          0.064755             0.386679   \n",
       "7              0.347568          0.058364             0.376079   \n",
       "8              0.332740          0.056974             0.365520   \n",
       "9              0.321683          0.050118             0.356542   \n",
       "10             0.321566          0.050247             0.369297   \n",
       "11             0.314348          0.046955             0.350028   \n",
       "12             0.309942          0.044662             0.352801   \n",
       "13             0.308258          0.041687             0.351998   \n",
       "14             0.303226          0.041618             0.339191   \n",
       "15             0.295645          0.039173             0.334929   \n",
       "16             0.289104          0.037410             0.331141   \n",
       "17             0.289060          0.036020             0.329829   \n",
       "18             0.287240          0.034961             0.324639   \n",
       "\n",
       "    Logistics Service_den  Logistics Service_op_den  \n",
       "0                0.423792                  0.434944  \n",
       "1                0.336228                  0.393300  \n",
       "2                0.322791                  0.381395  \n",
       "3                0.308780                  0.351190  \n",
       "4                0.293862                  0.343459  \n",
       "5                0.277365                  0.325717  \n",
       "6                0.260000                  0.312558  \n",
       "7                0.255891                  0.301364  \n",
       "8                0.236607                  0.289062  \n",
       "9                0.229625                  0.280352  \n",
       "10               0.232176                  0.282393  \n",
       "11               0.219233                  0.269319  \n",
       "12               0.214722                  0.273186  \n",
       "13               0.209821                  0.266369  \n",
       "14               0.207859                  0.260405  \n",
       "15               0.200656                  0.257768  \n",
       "16               0.196362                  0.251964  \n",
       "17               0.194047                  0.249853  \n",
       "18               0.189546                  0.247396  \n",
       "\n",
       "[19 rows x 53 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fracs = [0.1 ,0.3, 0.5, 0.7, 0.75, 0.8, 0.9, 1]\n",
    "tmp_data = []\n",
    "for i in range(10,105,5):\n",
    "    frac = i/100\n",
    "    r = generate_corpus_stats(experiment_name, data_path,frac=frac)\n",
    "    tmp_line = [frac]\n",
    "    for k, v in r.items():\n",
    "        tmp_line.append(v['asp_den'])\n",
    "        tmp_line.append(v['op_den'])\n",
    "        \n",
    "    tmp_data.append(tmp_line)\n",
    "\n",
    "cols = [frac]\n",
    "for k,v in r.items():\n",
    "    cols.append(f'{k}_den')\n",
    "    cols.append(f'{k}_op_den')\n",
    "dff = pd.DataFrame(tmp_data, columns=cols)\n",
    "dff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T02:18:12.040183Z",
     "start_time": "2019-09-06T02:18:12.023480Z"
    }
   },
   "outputs": [],
   "source": [
    "dff.to_csv(os.path.join(data_path, 'sample_density.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T09:16:15.484196Z",
     "start_time": "2019-09-09T09:16:15.477428Z"
    }
   },
   "outputs": [],
   "source": [
    "from data_preprocess import convert_text\n",
    "\n",
    "tt = convert_text( '这个不错肯定是正品???味道也对，洗完舒服的一批~而且幸运的是拿到了新包装')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新词发现功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T09:08:28.303883Z",
     "start_time": "2019-09-12T09:08:28.172910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irritation {'灼烧感', '辣辣的', '小疙瘩', '长痘痘', '眼睛 不舒服', '没有过敏', '耐受', '小红点', '没感到闷痘', '辣眼睛', '粉刺', '很痒', '不良反应', '出斑', '过敏 没有', '刺痛', '不刺激', '长痘', '脸发烫', '不耐受', '出痘', '温和', '说会痛', '长 痘', '刺痛感', '爆痘', '有点痛', '不过敏', '痘痘肌', '刺激', '有点痒', '刺刺的', '疙瘩', '用完长痘长闭口', '灼热感', '起 痘痘', '刺激感', '刺脸', '疼痛', '还痒', '红肿', '有点疼', '火辣辣的', '刺痛掉皮', '大爆痘', '闷痘', '起 痘', '脸上 痒', '起痘', '又疼', '痘痘肌用', '不适感', '白色 点点', '毛孔堵', '过敏现象', '长 痘痘', '痘肌', '洗完脸痛', '脸会痒痒', '又氧又疼', '不适', '刚擦上 有点热', '无过敏', '冒痘', '过敏', '脸可痛', '不长痘', '痒痒的', '用着 痒', '起痘痘', '痘痘'}\n",
      "打印冲突词 Irritation\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "experiment_name = 'skincare_op'\n",
    "runs_name = 'all_in_one'\n",
    "run_name = f'{runs_name}/checkpoint-4200'  # 有时需要加上checkpoint后缀\n",
    "data_path = f'/data/projects/bert_pytorch/{experiment_name}'\n",
    "frac=1\n",
    "\n",
    "r = generate_corpus_stats(experiment_name, data_path, sublist=['Irritation'], frac=1, verbose=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T09:08:03.576422Z",
     "start_time": "2019-09-12T09:08:03.559695Z"
    }
   },
   "outputs": [],
   "source": [
    "tt = set(('闭口冒出来', '没伤害', '小红点', '发红', '没过敏', '刺激性', '辣眼睛', '不良反应', '还长 痘', '生痛', '长痘', '烂脸', '火辣辣', '红疙瘩', '刺刺的', '疙瘩', '脸 烂', '刺激感', '火辣辣 痛', '爆豆', '起 痘', '又疼', '洗完 舒适', '长 痘痘', '眼睛周围 痛', '红 肿', '无过敏', '过敏', '不长痘', '长粉刺', '辣辣的', '痘痘', '致痘', '无刺激', '小疙瘩', '没长痘', '起疙瘩', '张 痘痘', '眼睛 肿', '没有过敏', '干疼', '不刺激', '脸上 痒痒', '还长痘', '发痒', '痘痘肌', '刺激', '看痘印说', '疼痛', '火辣辣的', '有一点疼', '有点辣', '痘痘肌用', '不耐反应', '过敏现象', '过敏反应', '不痒了', '痘肌', '有点刺', '耐受性', '满脸痘痘', '刺到眼睛', '耐受', '又痒', '脸 刺痛', '长痘痘', '起红', '会痛', '特别辣', '起 疹子', '痛感', '粉刺', '辣辣的感觉', '脸痛', '有点烧', '刺痛', '出痘', '温和', '长 痘', '爆痘', '会痒', '不过敏', '扎扎的疼', '脸肿', '很疼', '长闭口', '特别疼', '有点疼', '闷痘', '痘痘肌肤', '痒', '起痘', '刺眼', '不适感', '皮肤舒适', '刺痒', '不起痘', '发烫', '不适', '烧灼感', '爆了 痘', '刺眼镜', '起痘痘', '冒痘痘', '有红点', '火辣辣 疼', '冒 痘痘', '有点发热', '皮肤过敏', '柔和', '泛红', '刺痛感', '有点痛', '逗痘', '奇痒无比', '痒痒', '有点痒', '刺疼', '有痘痘', '起 痘痘', '红肿', '没有 过敏', '刺激感都', '发痘痘', '抹了疼', '青春痘', '脸会痒痒', '又氧又疼', '皮肤刺痛', '冒痘', '痘痘长'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T09:08:43.060501Z",
     "start_time": "2019-09-12T09:08:43.047210Z"
    }
   },
   "outputs": [],
   "source": [
    "dd = set(('灼烧感', '辣辣的', '小疙瘩', '长痘痘', '眼睛 不舒服', '没有过敏', '耐受', '小红点', '没感到闷痘', '辣眼睛', '粉刺', '很痒', '不良反应', '出斑', '过敏 没有', '刺痛', '不刺激', '长痘', '脸发烫', '不耐受', '出痘', '温和', '说会痛', '长 痘', '刺痛感', '爆痘', '有点痛', '不过敏', '痘痘肌', '刺激', '有点痒', '刺刺的', '疙瘩', '用完长痘长闭口', '灼热感', '起 痘痘', '刺激感', '刺脸', '疼痛', '还痒', '红肿', '有点疼', '火辣辣的', '刺痛掉皮', '大爆痘', '闷痘', '起 痘', '脸上 痒', '起痘', '又疼', '痘痘肌用', '不适感', '白色 点点', '毛孔堵', '过敏现象', '长 痘痘', '痘肌', '洗完脸痛', '脸会痒痒', '又氧又疼', '不适', '刚擦上 有点热', '无过敏', '冒痘', '过敏', '脸可痛', '不长痘', '痒痒的', '用着 痒', '起痘痘', '痘痘'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T09:08:50.295856Z",
     "start_time": "2019-09-12T09:08:50.286455Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'不耐受',\n",
       " '出斑',\n",
       " '刚擦上 有点热',\n",
       " '刺痛掉皮',\n",
       " '刺脸',\n",
       " '大爆痘',\n",
       " '很痒',\n",
       " '毛孔堵',\n",
       " '没感到闷痘',\n",
       " '洗完脸痛',\n",
       " '灼烧感',\n",
       " '灼热感',\n",
       " '用完长痘长闭口',\n",
       " '用着 痒',\n",
       " '痒痒的',\n",
       " '白色 点点',\n",
       " '眼睛 不舒服',\n",
       " '脸上 痒',\n",
       " '脸发烫',\n",
       " '脸可痛',\n",
       " '说会痛',\n",
       " '过敏 没有',\n",
       " '还痒'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.difference(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-16T07:51:20.250727Z",
     "start_time": "2019-09-16T07:51:20.186438Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils_skincare_v2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ae974cbdc852>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/projects/bert_pytorch/skincare_op/Greasy/cached_train_pytorch_model.bin_256'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/sk/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/sk/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils_skincare_v2'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "aa = torch.load('/data/projects/bert_pytorch/skincare_pa/Greasy/cached_train_pytorch_model.bin_256')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
