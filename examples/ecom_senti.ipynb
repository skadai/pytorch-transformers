{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 电商评论模型调用\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-16T06:01:20.264177Z",
     "start_time": "2019-09-16T06:01:10.073286Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEcomCommentMultiPolarV4(\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (kw_attention): SubtypeAttention(\n",
       "    (activation): Tanh()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (qa_outputs): ModuleList(\n",
       "    (0): Linear(in_features=768, out_features=4, bias=True)\n",
       "    (1): Linear(in_features=768, out_features=4, bias=True)\n",
       "    (2): Linear(in_features=768, out_features=4, bias=True)\n",
       "    (3): Linear(in_features=768, out_features=4, bias=True)\n",
       "    (4): Linear(in_features=768, out_features=4, bias=True)\n",
       "    (5): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (activation): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from run_ecom_senti import MODEL_CLASSES  \n",
    "\n",
    "task_name = 'skincare_patch'  # 本次任务名\n",
    "runs_name = 'all_in_one_ground' # 当前一次运行名称\n",
    "subdict = 'skincare' # 品类名称, 需提前将subtype定义写入 SUBTYPE.json文件\n",
    "target_device=\"cpu\"  \n",
    "# target_device=\"cuda:0\"  # 模型指定gpu或cpu\n",
    "config_path = f'/data/projects/bert_pytorch/{task_name}_out/{runs_name}/config.json'\n",
    "vocab_path = f'/data/projects/bert_pytorch/{task_name}_out/{runs_name}/vocab.txt'\n",
    "model_path = f'/data/projects/bert_pytorch/{task_name}_out/{runs_name}/checkpoint-4200/pytorch_model.bin' \n",
    "# 注意此处实际上用了checkpoint中的模型, 如需使用最终步模型, 修改对应路径即可\n",
    "\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES['ecom_senti']\n",
    "config = config_class.from_pretrained(config_path, num_labels=4)\n",
    "tokenizer = tokenizer_class.from_pretrained(vocab_path)\n",
    "model = model_class.from_pretrained(model_path, config=config)\n",
    "model.to(torch.device(target_device))  \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-16T03:07:02.000938Z",
     "start_time": "2019-09-16T03:07:01.948820Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "\n",
    "from data_preprocess import convert_text\n",
    "from utils_ecom_senti import (\n",
    "    RawResult, \n",
    "    SquadExample,\n",
    "    convert_examples_to_features,\n",
    "    convert_polar_examples_to_features, find_positions\n",
    ")\n",
    "from utils_glue import InputExample\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from mtl_manual import write_predictions\n",
    "\n",
    "def to_list(tensor):\n",
    "    return tensor.detach().cpu().tolist()\n",
    "\n",
    "\n",
    "# 加载trans_subtype\n",
    "TRANS_SUBTYPE = json.load(open(os.path.join(os.getcwd(), 'SUBTYPE.json'), 'r'))[subdict]\n",
    "subtype_list = list(TRANS_SUBTYPE.keys())\n",
    "\n",
    "\n",
    "# 极性映射关系\n",
    "label_map = {\n",
    "    '2': 5,\n",
    "    '0': 1,\n",
    "    '1': 3\n",
    "}\n",
    "\n",
    "\n",
    "def find_subtype(idx):\n",
    "    return subtype_list[idx]\n",
    "\n",
    "\n",
    "\n",
    "def calc_polar(text, opinions, inputs, seq_outputs, max_seq_length=256):\n",
    "\n",
    "    opinion_masks = []\n",
    "    examples = []\n",
    "    for r in opinions:\n",
    "        opinion_mask = [0] * max_seq_length\n",
    "        op_start, op_end = find_positions(text, [r['opinionTerm']])\n",
    "        if op_start == -2 or op_start > max_seq_length - 5:\n",
    "            opinion_mask[0] = 1\n",
    "        else:\n",
    "            for i in range(op_start, op_end):\n",
    "                opinion_mask[min(i+4, max_seq_length-1)] = 1\n",
    "        opinion_masks.append(opinion_mask)   \n",
    "    all_opinion_mask = torch.tensor(opinion_masks, dtype=torch.float32).to(torch.device(target_device))\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        inputs.update({\n",
    "          'opinion_mask':   all_opinion_mask,\n",
    "          'seq_embeddings': seq_outputs.repeat(len(opinion_masks),1,1) ,\n",
    "          'attention_mask': inputs['attention_mask'].repeat(len(opinion_masks),1)\n",
    "        })\n",
    "    \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "    return np.argmax(outputs.detach().cpu().numpy(),axis=1).tolist()\n",
    "\n",
    "\n",
    "def general_sentiment(text, tokenizer=tokenizer, model=model):\n",
    "    ## 目前处理不了长句子\n",
    "    text = text[:250]\n",
    "    start = time.time()\n",
    "    # 生成模型feature run 模型\n",
    "    example = SquadExample(\n",
    "                     qas_id=0,\n",
    "                     question_text=list(TRANS_SUBTYPE.values())[0],\n",
    "                     doc_tokens=convert_text(text),\n",
    "                     label=1\n",
    "\n",
    "    )\n",
    "\n",
    "    features = convert_examples_to_features(examples=[example],\n",
    "                                            tokenizer=tokenizer,\n",
    "                                            max_seq_length=256,\n",
    "                                            doc_stride=128,\n",
    "                                            max_query_length=20,\n",
    "                                            is_training=False,\n",
    "                                            label_list=[1,3,5],\n",
    "                                           trans_subtype=TRANS_SUBTYPE)\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long).to(torch.device(target_device))\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long).to(torch.device(target_device))\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long).to(torch.device(target_device))\n",
    "    all_question_ids = torch.tensor([-1 for f in features], dtype=torch.long).to(torch.device(target_device))\n",
    "    with torch.no_grad():\n",
    "        inputs = {\n",
    "              'input_ids':   all_input_ids,\n",
    "              'attention_mask': all_input_mask,\n",
    "              'token_type_ids': all_segment_ids,  # XLM don't use segment_ids\n",
    "              'question_ids':  all_question_ids,\n",
    "        }\n",
    "        time1 = time.time()\n",
    "        outputs =model(**inputs)\n",
    "\n",
    "        time2 = time.time()\n",
    "    all_results = []\n",
    "    all_op_results = []\n",
    "    \n",
    "    for i in range(len(outputs[0])):\n",
    "        \n",
    "        result = RawResult(unique_id = features[0].unique_id,\n",
    "                           start_logits = to_list(outputs[0][i][0]),\n",
    "                           end_logits = to_list(outputs[1][i][0]))\n",
    "        op_result = RawResult(unique_id = features[0].unique_id,\n",
    "                           start_logits = to_list(outputs[2][i][0]),\n",
    "                           end_logits = to_list(outputs[3][i][0]))\n",
    "\n",
    "   \n",
    "        all_results.append(result)\n",
    "        all_op_results.append(op_result)\n",
    "    \n",
    "    # 根据模型输出查找结果\n",
    "    ret = {\n",
    "        'text':  convert_text(text),\n",
    "        'opinions': []\n",
    "    }\n",
    "    idx = 0\n",
    "    kwargs = dict(n_best_size=5,\n",
    "                  max_answer_length=20, \n",
    "                  do_lower_case=True,\n",
    "                  verbose_logging=False,\n",
    "                  version_2_with_negative=True,\n",
    "                  null_score_diff_threshold=0)\n",
    "    for r, opr in (zip(all_results, all_op_results)):\n",
    "\n",
    "        asp, nbest_asp=write_predictions([example], features, [r], **kwargs) #特征词    \n",
    "        op, nbest_op=write_predictions([example], features, [opr], **kwargs) #情感词 \n",
    "        asp_ret = asp[0].replace(\" \",\"\")\n",
    "        op_ret = op[0].replace(\" \",\"\")\n",
    "        if len(asp_ret) > 1:\n",
    "            ret['opinions'].append({\n",
    "                'aspectSubtype' : find_subtype(idx),\n",
    "                'aspectTerm': asp_ret,\n",
    "                'opinionTerm': op_ret,\n",
    "            })\n",
    "        idx += 1\n",
    "        if idx > len(TRANS_SUBTYPE): break \n",
    "            \n",
    "            \n",
    "    time3 = time.time()\n",
    "\n",
    "    if len(ret['opinions']) > 0:\n",
    "        polars = calc_polar(example.doc_tokens, ret['opinions'], inputs, outputs[4])\n",
    "        time4 = time.time()\n",
    "        for op, polar in zip(ret['opinions'], polars):\n",
    "            if len(op['opinionTerm']) < 1:\n",
    "                op['polarity'] = 3\n",
    "            else:\n",
    "                op['polarity'] = label_map.get(str(polar),3)\n",
    "    time5 = time.time()\n",
    "#     print('预处理时间', time1 - start)\n",
    "#     print('模型时间', time2 - time1)\n",
    "#     print('后处理词时间', time3 - time2)\n",
    "#     print('极性时间', time4 - time3)\n",
    "#     print('极性时间', time5 - time4)\n",
    "\n",
    "    return ret, [time1 - start,time2 - time1,time3 - time2,time4 - time3,time5 - time4]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本测试\n",
    "\n",
    "- GPU 单进程 0.2s 一条 GPU利用率8%\n",
    "- CPU 单进程 0.5s 一条 CPU利用率超过100%(多核)\n",
    "\n",
    "```python\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for i in range(100):\n",
    "    p = general_sentiment(text)\n",
    "print('cost time', time.time() - start)\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-16T03:07:21.191889Z",
     "start_time": "2019-09-16T03:07:20.814438Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time 0.3654806613922119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': '这个真的不推荐,眼霜还是买大牌吧,完全不吸收,担心会长脂肪粒',\n",
       " 'opinions': [{'aspectSubtype': 'Fat Granule',\n",
       "   'aspectTerm': '脂肪粒',\n",
       "   'opinionTerm': '担心会长脂肪粒',\n",
       "   'polarity': 3}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"这个真的不推荐,眼霜还是买大牌吧,完全不吸收,担心会长脂肪粒\"\n",
    "timer = []\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    ret, t = general_sentiment(text)\n",
    "#     timer.append(t)\n",
    "print('cost time', time.time() - start)\n",
    "ret\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对比godolphin结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-16T03:07:39.950608Z",
     "start_time": "2019-09-16T03:07:39.620679Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': True,\n",
       " 'data': {'data': [{'aspectSubtype': 'Fat Granule',\n",
       "    'aspectType': 'Product',\n",
       "    'polarity': 3,\n",
       "    'aspectTerm': ['脂肪粒'],\n",
       "    'opinionTerm': [''],\n",
       "    'aspect_confidence': 1,\n",
       "    'opinion_confidence': 0.76811594,\n",
       "    'subtype_strategy': 'R102/n-脂肪粒/a-3,3/lc',\n",
       "    'opinion_strategy': '{}NEU/p',\n",
       "    'mapping': '',\n",
       "    'summary': '脂肪粒'},\n",
       "   {'aspectSubtype': 'Brand Equity',\n",
       "    'aspectType': 'Branding',\n",
       "    'polarity': 1,\n",
       "    'aspectTerm': ['大牌'],\n",
       "    'opinionTerm': ['担心'],\n",
       "    'aspect_confidence': 1,\n",
       "    'opinion_confidence': 0.80595875,\n",
       "    'subtype_strategy': 'R102/n-大牌/a-1,1/lc',\n",
       "    'opinion_strategy': 's/担心/oNEG/p/1-KPT/g/1',\n",
       "    'mapping': '',\n",
       "    'summary': '大牌担心'}],\n",
       "  'lang': '',\n",
       "  'is_spam': False,\n",
       "  'model_version': '',\n",
       "  'text_polarity': 1}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "payload = {\n",
    "    'text': text,\n",
    "    'category': 'SkinCare'  # 这里替换为godolphin对应的品类\n",
    "}\n",
    "headers = {\n",
    "    'Content-Type': \"application/json\",\n",
    "    'Cache-Control': \"no-cache\",\n",
    "    }\n",
    "\n",
    "r = requests.post('http://godolphin.ym:30078/analysis', json=payload, headers=headers)\n",
    "r.json()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
